# Call Graph 性能优化指南

## 🚀 性能问题

对于大型项目（2000+ 文件，12000+ 函数），标准模式分析速度可能较慢。

## ✨ 优化方案

我们提供了**性能优化模式**，采用以下技术：

### 1. 多进程并行处理
- 使用 Python multiprocessing 并行处理文件
- 默认使用 (CPU核心数 - 1) 个工作进程
- 大幅提升文件处理速度

### 2. 批量数据库操作
- 批量插入数据库，减少 I/O 次数
- 使用事务优化，提升写入性能
- 可自定义批次大小

### 3. 进度显示
- 实时显示处理进度
- 显示处理速度统计
- 更好的用户体验

## 📖 使用方法

### 基本用法

使用 `--fast` 参数启用性能优化模式：

```bash
python call-graph.py --database myproject.db analyze /path/to/project --clear --fast
```

### 完整参数

```bash
python call-graph.py --database myproject.db analyze /path/to/project \
  --clear \
  --fast \
  --workers 8 \
  --batch-size 200
```

### 参数说明

| 参数 | 缩写 | 默认值 | 说明 |
|------|------|--------|------|
| `--fast` | `-f` | 否 | 启用性能优化模式 |
| `--workers` | `-w` | CPU核心数-1 | 工作进程数量 |
| `--batch-size` | `-b` | 100 | 批量插入数据库的大小 |

## 🎯 性能对比

### 标准模式
```bash
# 2000 文件，12000 函数
时间: ~10-15 分钟
速度: ~2-3 文件/秒
```

### 优化模式（8核 CPU）
```bash
# 2000 文件，12000 函数
时间: ~2-3 分钟
速度: ~10-15 文件/秒
```

**性能提升**: 约 **5-7 倍**

## 💡 最佳实践

### 1. 选择合适的工作进程数

```bash
# CPU 密集型，建议使用 CPU 核心数 - 1
python call-graph.py --database myproject.db analyze /path/to/project \
  --fast --workers 7  # 8核CPU
```

### 2. 根据项目大小调整批次大小

```bash
# 小项目（< 1000 文件）
--batch-size 50

# 中型项目（1000-5000 文件）
--batch-size 100

# 大型项目（> 5000 文件）
--batch-size 200
```

### 3. 排除不需要的目录

```bash
python call-graph.py --database myproject.db analyze /path/to/project \
  --fast \
  --exclude "node_modules,venv,build,dist,target,test,tests"
```

## 📊 输出示例

使用性能优化模式时的输出：

```
使用性能优化模式（多进程并行处理）
开始分析项目: /path/to/myproject
使用 7 个工作进程
找到 2143 个源代码文件

第一遍扫描：提取函数定义（并行处理）...
提取函数: [████████████████████████████████████████] 2143/2143 (100.0%)
共提取 12456 个函数定义

保存函数定义到数据库（批量操作，批次大小：100）...
保存符号: [████████████████████████████████████████] 12456/12456 (100.0%)

第二遍扫描：提取调用关系（并行处理）...
提取调用: [████████████████████████████████████████] 2143/2143 (100.0%)
共提取 45678 个调用关系

保存调用关系到数据库（批量操作，批次大小：100）...
保存调用: [████████████████████████████████████████] 45678/45678 (100.0%)

============================================================
分析完成！
============================================================
总耗时: 142.35 秒
处理速度: 15.1 文件/秒
总符号数: 12456
总调用关系: 45678

按语言统计:
  python         :   4523 个符号
  javascript     :   3412 个符号
  typescript     :   2134 个符号
  java           :   1876 个符号
  cpp            :    511 个符号
============================================================
```

## ⚡ 性能提示

### 1. 使用 SSD 硬盘
- SQLite 数据库性能依赖磁盘 I/O
- SSD 可以显著提升性能

### 2. 增加系统内存
- 多进程并行需要更多内存
- 建议至少 4GB 可用内存

### 3. 关闭其他程序
- 释放 CPU 资源
- 避免资源竞争

### 4. 首次分析使用 --clear
```bash
python call-graph.py --database myproject.db analyze /path/to/project --clear --fast
```

### 5. 不要过度使用工作进程
```bash
# 不推荐：超过 CPU 核心数
--workers 16  # 8核CPU

# 推荐：CPU 核心数 - 1 或 - 2
--workers 6   # 8核CPU
```

## 🔍 故障排除

### 问题 1: 内存不足

**症状**: 进程被杀死或系统卡顿

**解决**: 减少工作进程数
```bash
python call-graph.py --database myproject.db analyze /path/to/project \
  --fast --workers 4
```

### 问题 2: 数据库锁定

**症状**: SQLite database is locked

**解决**: 关闭其他访问数据库的进程

### 问题 3: 进程启动失败

**症状**: multiprocessing errors

**解决**: 确保脚本作为模块运行
```bash
# 正确
python call-graph.py ...
python -m call_graph ...

# 错误（可能导致问题）
# 直接在 IDE 中运行多进程代码
```

## 📚 技术细节

### 架构说明

```
主进程
  ├─ 文件收集
  ├─ 工作进程池 (multiprocessing.Pool)
  │    ├─ Worker 1: 处理文件 1, 11, 21...
  │    ├─ Worker 2: 处理文件 2, 12, 22...
  │    ├─ Worker 3: 处理文件 3, 13, 23...
  │    └─ ...
  └─ 批量数据库写入（主进程）
```

### 性能瓶颈分析

1. **标准模式瓶颈**:
   - 串行处理文件
   - 逐个插入数据库
   - 无进度显示

2. **优化后改进**:
   - 并行处理文件（CPU）
   - 批量插入（I/O）
   - 进度条（用户体验）

## 🎯 总结

### 何时使用优化模式

- ✅ 大型项目（>1000 文件）
- ✅ 需要快速分析
- ✅ 有多核 CPU
- ✅ 内存充足（>4GB）

### 何时使用标准模式

- ✅ 小型项目（<100 文件）
- ✅ 内存受限
- ✅ 单核 CPU
- ✅ 调试模式

### 推荐命令

```bash
# 大型项目 - 性能优化模式
python call-graph.py --database myproject.db analyze /path/to/project \
  --clear --fast --workers 7 --batch-size 200

# 小型项目 - 标准模式
python call-graph.py --database myproject.db analyze /path/to/project --clear
```

---

**提示**: 性能优化模式与所有查询功能完全兼容，分析后的数据库格式相同。

